{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f680dc0",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5f6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::pcre==8.45=h295c915_0\n",
      "  - defaults/noarch::python-dateutil==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::bleach==3.3.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::jupyterlab_widgets==1.0.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::nbconvert==6.1.0=py37h06a4308_0\n",
      "  - defaults/noarch::ipywidgets==7.6.3=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::importlib-metadata==3.10.0=py37h06a4308_0\n",
      "  - defaults/noarch::testpath==0.5.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::python==3.7.10=h12debd9_4\n",
      "  - defaults/linux-64::libxml2==2.9.12=h03d6c58_0\n",
      "  - defaults/linux-64::pyqt==5.9.2=py37h05f1152_2\n",
      "  - defaults/linux-64::gstreamer==1.14.0=h28cd5cc_2\n",
      "  - defaults/noarch::jupyterlab_pygments==0.1.2=py_0\n",
      "  - defaults/noarch::prometheus_client==0.11.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::argon2-cffi==20.1.0=py37h27cfd23_1\n",
      "  - defaults/linux-64::libgcc-ng==9.3.0=h5101ec6_17\n",
      "  - defaults/noarch::jupyter_console==6.4.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::pickleshare==0.7.5=pyhd3eb1b0_1003\n",
      "  - defaults/noarch::six==1.16.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::wheel==0.36.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::pygments==2.9.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::packaging==21.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::mistune==0.8.4=py37h14c3975_1001\n",
      "  - defaults/noarch::typing_extensions==3.10.0.0=pyh06a4308_0\n",
      "  - defaults/noarch::parso==0.8.2=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py37_0\n",
      "  - defaults/linux-64::setuptools==52.0.0=py37h06a4308_0\n",
      "  - defaults/linux-64::glib==2.69.0=h5202010_0\n",
      "  - defaults/noarch::decorator==5.0.9=pyhd3eb1b0_0\n",
      "  - defaults/noarch::defusedxml==0.7.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::nbformat==5.1.3=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::certifi==2021.5.30=py37h06a4308_0\n",
      "  - defaults/linux-64::terminado==0.9.4=py37h06a4308_0\n",
      "  - defaults/noarch::jupyter_client==6.1.12=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::pyrsistent==0.17.3=py37h7b6447c_0\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::async_generator==1.10=py37h28b3542_0\n",
      "  - defaults/linux-64::qt==5.9.7=h5867ecd_1\n",
      "  - defaults/noarch::jsonschema==3.2.0=py_2\n",
      "  - defaults/linux-64::libpng==1.6.37=hbc83047_0\n",
      "  - defaults/noarch::attrs==21.2.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::traitlets==5.0.5=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::openssl==1.1.1k=h27cfd23_0\n",
      "  - defaults/linux-64::sip==4.19.8=py37hf484d3e_0\n",
      "  - defaults/linux-64::freetype==2.10.4=h5ab3b9f_0\n",
      "  - defaults/noarch::backcall==0.2.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::libstdcxx-ng==9.3.0=hd4cf53a_17\n",
      "  - defaults/linux-64::dbus==1.13.18=hb2f20db_0\n",
      "  - defaults/linux-64::tk==8.6.10=hbc83047_0\n",
      "  - defaults/linux-64::pyzmq==20.0.0=py37h2531618_1\n",
      "  - defaults/linux-64::gst-plugins-base==1.14.0=h8213a91_2\n",
      "  - defaults/noarch::wcwidth==0.2.5=py_0\n",
      "  - defaults/linux-64::entrypoints==0.3=py37_0\n",
      "  - defaults/linux-64::ipython==7.22.0=py37hb070fc8_0\n",
      "  - defaults/linux-64::fontconfig==2.13.1=h6c09931_0\n",
      "  - defaults/linux-64::zeromq==4.3.4=h2531618_0\n",
      "  - defaults/noarch::send2trash==1.5.0=pyhd3eb1b0_1\n",
      "  - defaults/noarch::nest-asyncio==1.5.1=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::jpeg==9b=h024ee3a_2\n",
      "  - defaults/linux-64::sqlite==3.36.0=hc218d9a_0\n",
      "  - defaults/linux-64::libsodium==1.0.18=h7b6447c_0\n",
      "  - defaults/linux-64::libffi==3.3=he6710b0_2\n",
      "  - defaults/noarch::ipython_genutils==0.2.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::libxcb==1.14=h7b6447c_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py37_7\n",
      "  - defaults/noarch::pyparsing==2.4.7=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::ipykernel==5.3.4=py37h5ca1d4c_0\n",
      "  - defaults/linux-64::pandocfilters==1.4.3=py37h06a4308_1\n",
      "  - defaults/linux-64::cffi==1.14.6=py37h400218f_0\n",
      "  - defaults/linux-64::jedi==0.17.0=py37_0\n",
      "  - defaults/noarch::zipp==3.5.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::qtconsole==5.1.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::prompt_toolkit==3.0.17=hd3eb1b0_0\n",
      "  - defaults/linux-64::xz==5.2.5=h7b6447c_0\n",
      "  - defaults/linux-64::webencodings==0.5.1=py37_1\n",
      "  - defaults/linux-64::ncurses==6.2=he6710b0_1\n",
      "  - defaults/noarch::jinja2==3.0.1=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::readline==8.1=h27cfd23_0\n",
      "  - defaults/noarch::prompt-toolkit==3.0.17=pyh06a4308_0\n",
      "  - defaults/linux-64::libuuid==1.0.3=h1bed415_2\n",
      "  - defaults/noarch::ptyprocess==0.7.0=pyhd3eb1b0_2\n",
      "  - defaults/noarch::pexpect==4.8.0=pyhd3eb1b0_3\n",
      "  - defaults/linux-64::jupyter_core==4.7.1=py37h06a4308_0\n",
      "  - defaults/linux-64::expat==2.4.1=h2531618_2\n",
      "  - defaults/linux-64::tornado==6.1=py37h27cfd23_0\n",
      "  - defaults/linux-64::icu==58.2=he6710b0_3\n",
      "  - defaults/linux-64::markupsafe==2.0.1=py37h27cfd23_0\n",
      "  - defaults/noarch::qtpy==1.9.0=py_0\n",
      "  - defaults/linux-64::pip==21.1.3=py37h06a4308_0\n",
      "  - defaults/noarch::importlib_metadata==3.10.0=hd3eb1b0_0\n",
      "  - defaults/noarch::pycparser==2.20=py_2\n",
      "  - defaults/linux-64::notebook==6.4.0=py37h06a4308_0\n",
      "  - defaults/linux-64::zlib==1.2.11=h7b6447c_3\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/blake/anaconda3/envs/gptneo6B\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=11.1\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    blas-1.0                   |              mkl           6 KB\n",
      "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
      "    numpy-1.20.3               |   py37hf144106_0          23 KB\n",
      "    pytorch-1.9.0              |py3.7_cuda11.1_cudnn8.0.5_0        1.44 GB  pytorch\n",
      "    torchaudio-0.9.0           |             py37         4.4 MB  pytorch\n",
      "    torchvision-0.10.0         |       py37_cu111        29.0 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.47 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
      "  cudatoolkit        nvidia/linux-64::cudatoolkit-11.1.74-h6bb024c_0\n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0\n",
      "  gmp                pkgs/main/linux-64::gmp-6.2.1-h2531618_2\n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.3.0-h06a4308_3350\n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0\n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.15-h63c8f33_5\n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0\n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0\n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0\n",
      "  libuv              pkgs/main/linux-64::libuv-1.40.0-h7b6447c_0\n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0\n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h2531618_0\n",
      "  mkl                pkgs/main/linux-64::mkl-2021.3.0-h06a4308_520\n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0\n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.0-py37h42c9631_2\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0\n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1\n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-hff7bd54_1\n",
      "  numpy              pkgs/main/linux-64::numpy-1.20.3-py37hf144106_0\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.20.3-py37h74d4b33_0\n",
      "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.0-hd408876_0\n",
      "  openjpeg           pkgs/main/linux-64::openjpeg-2.3.0-h05c96fa_1\n",
      "  pillow             pkgs/main/linux-64::pillow-8.3.1-py37h2c7a002_0\n",
      "  pytorch            pytorch/linux-64::pytorch-1.9.0-py3.7_cuda11.1_cudnn8.0.5_0\n",
      "  torchaudio         pytorch/linux-64::torchaudio-0.9.0-py37\n",
      "  torchvision        pytorch/linux-64::torchvision-0.10.0-py37_cu111\n",
      "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-1.9.0        | 1.44 GB   | ##################################### | 100% \n",
      "torchvision-0.10.0   | 29.0 MB   | ##################################### | 100% \n",
      "torchaudio-0.9.0     | 4.4 MB    | ##################################### | 100% \n",
      "libidn2-2.3.2        | 81 KB     | ##################################### | 100% \n",
      "numpy-1.20.3         | 23 KB     | ##################################### | 100% \n",
      "blas-1.0             | 6 KB      | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / b'By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\\n'\n",
      "done\n",
      "Cloning into 'mesh-transformer-jax'...\n",
      "remote: Enumerating objects: 643, done.\u001b[K\n",
      "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
      "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
      "remote: Total 643 (delta 240), reused 225 (delta 200), pack-reused 349\u001b[K\n",
      "Receiving objects: 100% (643/643), 180.46 KiB | 2.15 MiB/s, done.\n",
      "Resolving deltas: 100% (420/420), done.\n",
      "Collecting git+https://github.com/deepmind/dm-haiku (from -r mesh-transformer-jax/requirements.txt (line 10))\n",
      "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-h2faerho\n",
      "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-h2faerho\n",
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness/ (from -r mesh-transformer-jax/requirements.txt (line 11))\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness/ to /tmp/pip-req-build-xnh49dc7\n",
      "  Running command git clone -q https://github.com/EleutherAI/lm-evaluation-harness/ /tmp/pip-req-build-xnh49dc7\n",
      "Collecting numpy~=1.19.5\n",
      "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting transformers~=4.8.2\n",
      "  Using cached transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
      "Collecting tqdm~=4.45.0\n",
      "  Using cached tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting setuptools~=51.3.3\n",
      "  Using cached setuptools-51.3.3-py3-none-any.whl (786 kB)\n",
      "Collecting wandb~=0.10.22\n",
      "  Using cached wandb-0.10.33-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting einops~=0.3.0\n",
      "  Using cached einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting requests~=2.25.1\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting fabric~=2.6.0\n",
      "  Using cached fabric-2.6.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting optax==0.0.6\n",
      "  Using cached optax-0.0.6-py3-none-any.whl (96 kB)\n",
      "Collecting ray[default]==1.4.1\n",
      "  Using cached ray-1.4.1-cp37-cp37m-manylinux2014_x86_64.whl (51.6 MB)\n",
      "Collecting jax~=0.2.12\n",
      "  Downloading jax-0.2.18.tar.gz (708 kB)\n",
      "\u001b[K     |████████████████████████████████| 708 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask~=1.1.2\n",
      "  Using cached Flask-1.1.4-py2.py3-none-any.whl (94 kB)\n",
      "Collecting cloudpickle~=1.3.0\n",
      "  Using cached cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-cpu~=2.5.0\n",
      "  Using cached tensorflow_cpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (168.3 MB)\n",
      "Collecting google-cloud-storage~=1.36.2\n",
      "  Using cached google_cloud_storage-1.36.2-py2.py3-none-any.whl (97 kB)\n",
      "Collecting smart_open[gcs]\n",
      "  Using cached smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting func_timeout\n",
      "  Using cached func_timeout-4.3.5-py3-none-any.whl\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.0.3-py3-none-any.whl\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.67.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 661 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Using cached uvicorn-0.14.0-py3-none-any.whl (50 kB)\n",
      "Collecting absl-py>=0.7.1\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting jmp>=0.0.2\n",
      "  Using cached jmp-0.0.2-py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from dm-haiku==0.0.5.dev0->-r mesh-transformer-jax/requirements.txt (line 10)) (3.10.0.0)\n",
      "Collecting black==20.8b1\n",
      "  Using cached black-20.8b1-py3-none-any.whl\n",
      "Collecting best_download>=0.0.6\n",
      "  Using cached best_download-0.0.7-py3-none-any.whl (4.5 kB)\n",
      "Collecting datasets>=1.2.1\n",
      "  Downloading datasets-1.10.2-py3-none-any.whl (542 kB)\n",
      "\u001b[K     |████████████████████████████████| 542 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click>=7.1\n",
      "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting scikit-learn>=0.24.1\n",
      "  Using cached scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Requirement already satisfied: torch>=1.7 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (1.9.0)\n",
      "Collecting sqlitedict==1.6.0\n",
      "  Using cached sqlitedict-1.6.0-py3-none-any.whl\n",
      "Collecting pytablewriter==0.58.0\n",
      "  Using cached pytablewriter-0.58.0-py3-none-any.whl (96 kB)\n",
      "Collecting sacrebleu==1.5.0\n",
      "  Using cached sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "Collecting pycountry==20.7.3\n",
      "  Using cached pycountry-20.7.3-py2.py3-none-any.whl\n",
      "Collecting numexpr==2.7.2\n",
      "  Using cached numexpr-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (471 kB)\n",
      "Collecting lm_dataformat==0.0.19\n",
      "  Using cached lm_dataformat-0.0.19-py3-none-any.whl (5.4 kB)\n",
      "Collecting pytest==6.2.3\n",
      "  Using cached pytest-6.2.3-py3-none-any.whl (280 kB)\n",
      "Collecting pybind11==2.6.2\n",
      "  Using cached pybind11-2.6.2-py2.py3-none-any.whl (191 kB)\n",
      "Collecting tqdm-multiprocess==0.0.11\n",
      "  Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Collecting zstandard==0.15.2\n",
      "  Using cached zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
      "Collecting jsonlines==2.0.0\n",
      "  Using cached jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
      "Collecting mock==4.0.3\n",
      "  Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting openai==0.6.4\n",
      "  Using cached openai-0.6.4-py3-none-any.whl\n",
      "Collecting jaxlib>=0.1.37\n",
      "  Using cached jaxlib-0.1.69-cp37-none-manylinux2010_x86_64.whl (46.5 MB)\n",
      "Collecting chex>=0.0.4\n",
      "  Using cached chex-0.0.8-py3-none-any.whl (57 kB)\n",
      "Collecting regex>=2020.1.8\n",
      "  Using cached regex-2021.7.6-cp37-cp37m-manylinux2014_x86_64.whl (721 kB)\n",
      "Collecting toml>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting typed-ast>=1.4.0\n",
      "  Using cached typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
      "Collecting pathspec<1,>=0.6\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting ujson\n",
      "  Using cached ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5\n",
      "  Using cached tcolorpy-0.1.1-py3-none-any.whl (8.0 kB)\n",
      "Collecting msgfy<1,>=0.1.0\n",
      "  Using cached msgfy-0.1.0-py3-none-any.whl (4.3 kB)\n",
      "Collecting typepy[datetime]<2,>=1.1.1\n",
      "  Downloading typepy-1.2.0-py3-none-any.whl (31 kB)\n",
      "Collecting pathvalidate<3,>=2.3.0\n",
      "  Using cached pathvalidate-2.4.1-py3-none-any.whl (18 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Using cached mbstrdecoder-1.0.1-py3-none-any.whl (7.8 kB)\n",
      "Collecting tabledata<2,>=1.1.3\n",
      "  Downloading tabledata-1.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting DataProperty<2,>=0.50.0\n",
      "  Downloading DataProperty-0.52.0-py3-none-any.whl (26 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Using cached py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (3.10.0)\n",
      "Requirement already satisfied: packaging in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (21.0)\n",
      "Collecting pluggy<1.0.0a1,>=0.12\n",
      "  Using cached pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gpustat\n",
      "  Using cached gpustat-0.6.0-py3-none-any.whl\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting redis>=3.5.0\n",
      "  Using cached redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "Collecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.39.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Using cached py_spy-0.3.7-py2.py3-none-manylinux1_x86_64.whl (3.1 MB)\n",
      "Collecting aiohttp-cors\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: jsonschema in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (3.2.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (0.11.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting opencensus\n",
      "  Using cached opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting aioredis\n",
      "  Using cached aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.15.3\n",
      "  Using cached protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Using cached msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "Collecting pydantic>=1.8\n",
      "  Using cached pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "Collecting colorful\n",
      "  Using cached colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (1.16.0)\n",
      "Collecting psutil>=5.0.0\n",
      "  Using cached psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Using cached sentry_sdk-1.3.0-py2.py3-none-any.whl (133 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Using cached subprocess32-3.5.4-py3-none-any.whl\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from wandb~=0.10.22->-r mesh-transformer-jax/requirements.txt (line 5)) (2.8.2)\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Collecting configparser>=3.8.1\n",
      "  Using cached configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from requests~=2.25.1->-r mesh-transformer-jax/requirements.txt (line 7)) (2021.5.30)\n",
      "Collecting pathlib2\n",
      "  Using cached pathlib2-2.3.6-py2.py3-none-any.whl (17 kB)\n",
      "Collecting invoke<2.0,>=1.3\n",
      "  Using cached invoke-1.6.0-py3-none-any.whl (212 kB)\n",
      "Collecting paramiko>=2.4\n",
      "  Using cached paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
      "Collecting opt_einsum\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting click>=7.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous<2.0,>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug<2.0,>=0.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting Jinja2<3.0,>=2.10.1\n",
      "  Using cached Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from tensorflow-cpu~=2.5.0->-r mesh-transformer-jax/requirements.txt (line 16)) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting six>=1.13.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting grpcio>=1.28.1\n",
      "  Using cached grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting google-auth<2.0dev,>=1.11.0\n",
      "  Downloading google_auth-1.33.1-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Using cached google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Using cached google_resumable_media-1.3.1-py2.py3-none-any.whl (75 kB)\n",
      "Collecting rehash\n",
      "  Using cached rehash-1.0.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting dm-tree>=0.1.5\n",
      "  Using cached dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\n",
      "Collecting toolz>=0.9.0\n",
      "  Using cached toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "Collecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Using cached pyarrow-4.0.1-cp37-cp37m-manylinux2014_x86_64.whl (21.8 MB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.8 MB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Using cached smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Using cached google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting pytz\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Using cached google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage~=1.36.2->-r mesh-transformer-jax/requirements.txt (line 17)) (2.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (3.5.0)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1.2->-r mesh-transformer-jax/requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from packaging->pytest==6.2.3->lm-eval-harness==0.0.1->-r mesh-transformer-jax/requirements.txt (line 11)) (2.4.7)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Using cached PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "Collecting cryptography>=2.5\n",
      "  Using cached cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Using cached bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: wcwidth in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from ftfy->-r mesh-transformer-jax/requirements.txt (line 20)) (0.2.5)\n",
      "Collecting starlette==0.14.2\n",
      "  Using cached starlette-0.14.2-py3-none-any.whl (60 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting asgiref>=3.3.4\n",
      "  Using cached asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting hiredis\n",
      "  Using cached hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "Collecting blessings>=1.6\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Using cached nvidia_ml_py3-7.352.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jsonschema->ray[default]==1.4.1->-r mesh-transformer-jax/requirements.txt (line 12)) (0.17.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Using cached opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Building wheels for collected packages: dm-haiku, lm-eval-harness, jax\n",
      "  Building wheel for dm-haiku (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dm-haiku: filename=dm_haiku-0.0.5.dev0-py3-none-any.whl size=284723 sha256=e88c6acfc287d5415c25f0c3cdc6ae1ef4354c1b7e6eee0225b01ccbb9b5f2f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_46ruac4/wheels/06/28/69/ebaac5b2435641427299f29d88d005fb4e2627f4a108f0bdbc\n",
      "  Building wheel for lm-eval-harness (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lm-eval-harness: filename=lm_eval_harness-0.0.1-py3-none-any.whl size=100832 sha256=e961b21a66e611dfc78564794b20569b9ffea22ee466de007d1f4c5edd047b59\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_46ruac4/wheels/35/22/ec/71da337686fde904ec27f675d1bf73c4f253c48a6174d822b0\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.2.18-py3-none-any.whl size=815085 sha256=1ab3ae41310c8a9aa47aee2430fe5a0785f726f7b6ab8de7e981c61d6be9917d\n",
      "  Stored in directory: /home/blake/.cache/pip/wheels/63/e6/7e/6ec54acc84c8dddca4e1d25a41bce1653181b55e789461009a\n",
      "Successfully built dm-haiku lm-eval-harness jax\n",
      "Installing collected packages: chardet, six, pyasn1, mbstrdecoder, urllib3, typing-extensions, typepy, setuptools, rsa, pytz, pyasn1-modules, protobuf, multidict, idna, cachetools, yarl, requests, oauthlib, numpy, googleapis-common-protos, google-auth, async-timeout, tqdm, smmap, scipy, requests-oauthlib, regex, psutil, opt-einsum, opencensus-context, nvidia-ml-py3, joblib, hiredis, google-crc32c, google-api-core, flatbuffers, filelock, dill, DataProperty, click, blessings, aiohttp, absl-py, zstandard, xxhash, Werkzeug, ujson, typed-ast, toolz, toml, tokenizers, threadpoolctl, tensorboard-plugin-wit, tensorboard-data-server, tcolorpy, tabledata, sacremoses, rehash, redis, pyyaml, pynacl, pydantic, pyarrow, py-spy, py, portalocker, pluggy, pathvalidate, pathspec, pandas, opencensus, mypy-extensions, multiprocess, msgpack, msgfy, markdown, jsonlines, jaxlib, jax, iniconfig, huggingface-hub, grpcio, gpustat, google-resumable-media, google-cloud-core, google-auth-oauthlib, gitdb, fsspec, dm-tree, cryptography, colorama, cached-property, bcrypt, appdirs, aioredis, aiohttp-cors, wrapt, transformers, tqdm-multiprocess, termcolor, tensorflow-estimator, tensorboard, tabulate, subprocess32, starlette, sqlitedict, smart-open, shortuuid, sentry-sdk, scikit-learn, sacrebleu, ray, pytest, pytablewriter, pycountry, pybind11, promise, pathtools, pathlib2, paramiko, openai, numexpr, mock, lm-dataformat, keras-preprocessing, keras-nightly, jmp, Jinja2, itsdangerous, invoke, h5py, h11, google-pasta, google-cloud-storage, GitPython, gast, docker-pycreds, datasets, configparser, colorful, chex, black, best-download, astunparse, asgiref, wandb, uvicorn, tensorflow-cpu, optax, lm-eval-harness, func-timeout, ftfy, Flask, fastapi, fabric, einops, dm-haiku, cloudpickle\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 52.0.0.post20210125\n",
      "    Uninstalling setuptools-52.0.0.post20210125:\n",
      "      Successfully uninstalled setuptools-52.0.0.post20210125\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.0.1\n",
      "    Uninstalling Jinja2-3.0.1:\n",
      "      Successfully uninstalled Jinja2-3.0.1\n",
      "Successfully installed DataProperty-0.52.0 Flask-1.1.4 GitPython-3.1.18 Jinja2-2.11.3 Werkzeug-1.0.1 absl-py-0.13.0 aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 appdirs-1.4.4 asgiref-3.4.1 astunparse-1.6.3 async-timeout-3.0.1 bcrypt-3.2.0 best-download-0.0.7 black-20.8b1 blessings-1.7 cached-property-1.5.2 cachetools-4.2.2 chardet-4.0.0 chex-0.0.8 click-7.1.2 cloudpickle-1.3.0 colorama-0.4.4 colorful-0.5.4 configparser-5.0.2 cryptography-3.4.7 datasets-1.10.2 dill-0.3.4 dm-haiku-0.0.5.dev0 dm-tree-0.1.6 docker-pycreds-0.4.0 einops-0.3.0 fabric-2.6.0 fastapi-0.67.0 filelock-3.0.12 flatbuffers-1.12 fsspec-2021.7.0 ftfy-6.0.3 func-timeout-4.3.5 gast-0.4.0 gitdb-4.0.7 google-api-core-1.31.0 google-auth-1.33.1 google-auth-oauthlib-0.4.4 google-cloud-core-1.7.1 google-cloud-storage-1.36.2 google-crc32c-1.1.2 google-pasta-0.2.0 google-resumable-media-1.3.1 googleapis-common-protos-1.53.0 gpustat-0.6.0 grpcio-1.34.1 h11-0.12.0 h5py-3.1.0 hiredis-2.0.0 huggingface-hub-0.0.12 idna-2.10 iniconfig-1.1.1 invoke-1.6.0 itsdangerous-1.1.0 jax-0.2.18 jaxlib-0.1.69 jmp-0.0.2 joblib-1.0.1 jsonlines-2.0.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 lm-dataformat-0.0.19 lm-eval-harness-0.0.1 markdown-3.3.4 mbstrdecoder-1.0.1 mock-4.0.3 msgfy-0.1.0 msgpack-1.0.2 multidict-5.1.0 multiprocess-0.70.12.2 mypy-extensions-0.4.3 numexpr-2.7.2 numpy-1.19.5 nvidia-ml-py3-7.352.0 oauthlib-3.1.1 openai-0.6.4 opencensus-0.7.13 opencensus-context-0.1.2 opt-einsum-3.3.0 optax-0.0.6 pandas-1.3.0 paramiko-2.7.2 pathlib2-2.3.6 pathspec-0.9.0 pathtools-0.1.2 pathvalidate-2.4.1 pluggy-0.13.1 portalocker-2.3.0 promise-2.3 protobuf-3.17.3 psutil-5.8.0 py-1.10.0 py-spy-0.3.7 pyarrow-4.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybind11-2.6.2 pycountry-20.7.3 pydantic-1.8.2 pynacl-1.4.0 pytablewriter-0.58.0 pytest-6.2.3 pytz-2021.1 pyyaml-5.4.1 ray-1.4.1 redis-3.5.3 regex-2021.7.6 rehash-1.0.0 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 sacrebleu-1.5.0 sacremoses-0.0.45 scikit-learn-0.24.2 scipy-1.7.0 sentry-sdk-1.3.0 setuptools-51.3.3 shortuuid-1.0.1 six-1.15.0 smart-open-5.1.0 smmap-4.0.0 sqlitedict-1.6.0 starlette-0.14.2 subprocess32-3.5.4 tabledata-1.2.0 tabulate-0.8.9 tcolorpy-0.1.1 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-cpu-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 threadpoolctl-2.2.0 tokenizers-0.10.3 toml-0.10.2 toolz-0.11.1 tqdm-4.45.0 tqdm-multiprocess-0.0.11 transformers-4.8.2 typed-ast-1.4.3 typepy-1.2.0 typing-extensions-3.7.4.3 ujson-4.0.2 urllib3-1.26.6 uvicorn-0.14.0 wandb-0.10.33 wrapt-1.12.1 xxhash-2.0.2 yarl-1.6.3 zstandard-0.15.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
      "Processing ./mesh-transformer-jax\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting jax==0.2.12\n",
      "  Using cached jax-0.2.12-py3-none-any.whl\n",
      "Requirement already satisfied: jaxlib in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (0.1.69)\n",
      "Requirement already satisfied: opt-einsum in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jax==0.2.12) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.12 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jax==0.2.12) (1.19.5)\n",
      "Requirement already satisfied: absl-py in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jax==0.2.12) (0.13.0)\n",
      "Requirement already satisfied: scipy in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jaxlib) (1.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from jaxlib) (1.12)\n",
      "Requirement already satisfied: six in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from absl-py->jax==0.2.12) (1.15.0)\n",
      "Building wheels for collected packages: mesh-transformer\n",
      "  Building wheel for mesh-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mesh-transformer: filename=mesh_transformer-0.0.0-py3-none-any.whl size=23997 sha256=135edb31c6475067c0f584c6a3569c6def055b29c86f4fde7a5c07730c666274\n",
      "  Stored in directory: /home/blake/.cache/pip/wheels/c9/ba/dd/c9a70c308fb7b39ea69ae65957e1d7cf692dc7a8e14d24ee70\n",
      "Successfully built mesh-transformer\n",
      "Installing collected packages: mesh-transformer, jax\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.2.18\n",
      "    Uninstalling jax-0.2.18:\n",
      "      Successfully uninstalled jax-0.2.18\n",
      "Successfully installed jax-0.2.12 mesh-transformer-0.0.0\n",
      "Collecting git+https://github.com/finetuneanon/transformers@gpt-j\n",
      "  Cloning https://github.com/finetuneanon/transformers (to revision gpt-j) to /tmp/pip-req-build-bt3fqmlp\n",
      "  Running command git clone -q https://github.com/finetuneanon/transformers /tmp/pip-req-build-bt3fqmlp\n",
      "  Running command git checkout -b gpt-j --track origin/gpt-j\n",
      "  Switched to a new branch 'gpt-j'\n",
      "  Branch 'gpt-j' set up to track remote branch 'gpt-j' from 'origin'.\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (21.0)\n",
      "Requirement already satisfied: sacremoses in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (0.0.45)\n",
      "Requirement already satisfied: einops==0.3.0 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (0.3.0)\n",
      "Requirement already satisfied: filelock in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: requests in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (4.45.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (0.10.3)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from transformers==4.7.0.dev0) (2021.7.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from importlib-metadata->transformers==4.7.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from importlib-metadata->transformers==4.7.0.dev0) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from requests->transformers==4.7.0.dev0) (1.26.6)\n",
      "Requirement already satisfied: joblib in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: six in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: click in /home/blake/anaconda3/envs/gptneo6B/lib/python3.7/site-packages (from sacremoses->transformers==4.7.0.dev0) (7.1.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.7.0.dev0-py3-none-any.whl size=2405405 sha256=6db091ca194ac2fba67a4baaaabd41f5ca036092f4d0cc70d943041edb640cfd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4mwmamf6/wheels/53/9c/72/5c20589e8ea50123617a333d385c0d534a4d9b24b0c2289f48\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.12\n",
      "    Uninstalling huggingface-hub-0.0.12:\n",
      "      Successfully uninstalled huggingface-hub-0.0.12\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.8.2\n",
      "    Uninstalling transformers-4.8.2:\n",
      "      Successfully uninstalled transformers-4.8.2\n",
      "Successfully installed huggingface-hub-0.0.8 transformers-4.7.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia -y\n",
    "\n",
    "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
    "!pip install -r mesh-transformer-jax/requirements.txt\n",
    "\n",
    "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
    "!pip install mesh-transformer-jax/ jax==0.2.12 jaxlib -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "!pip install git+https://github.com/finetuneanon/transformers@gpt-j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c347a8e",
   "metadata": {},
   "source": [
    "## Get the actual GPT-J model [Source](https://github.com/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971f231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-25 03:07:27--  https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
      "Resolving the-eye.eu (the-eye.eu)... 162.213.130.242\n",
      "Connecting to the-eye.eu (the-eye.eu)|162.213.130.242|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "\n",
      "real\t0m0.201s\n",
      "user\t0m0.000s\n",
      "sys\t0m0.006s\n",
      "\n",
      "real\t0m50.893s\n",
      "user\t0m11.959s\n",
      "sys\t0m12.092s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
    "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
    "\n",
    "!time tar -I zstd -xf step_383500_slim.tar.zstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046b59b",
   "metadata": {},
   "source": [
    "## Convert to torch [Source](https://gist.github.com/finetuneanon/ee196c6cd16af1de4ca444862414683a) Credit:[finetuneanon](https://github.com/finetuneanon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8db4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1334  100  1334    0     0   7058      0 --:--:-- --:--:-- --:--:--  7021\n"
     ]
    }
   ],
   "source": [
    "!mkdir gpt-j-6B\n",
    "!curl https://gist.githubusercontent.com/finetuneanon/a55bdb3f5881e361faef0e96e1d41f09/raw/e5a38dad34ff42bbad188afd5e4fdb2ab2eacb6d/gpt-j-6b.json > gpt-j-6B/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a4e21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading shards for part 0\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.wte.bias torch.Size([4096])\n",
      "< (8, 6300, 4096) to (1, 50400, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> transformer.wte.weight torch.Size([4096, 50400])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.0.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.0.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.0.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.0.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.0.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.0.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.0.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.0.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.0.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.0.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.1.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.1.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.1.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.1.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.1.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.1.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "loading shards for part 1\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.1.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.1.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.1.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.1.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.10.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.10.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.10.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.10.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.10.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.10.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.10.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.10.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.10.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.10.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.11.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.11.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.11.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.11.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 2\n",
      "read from checkpoint\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.11.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.11.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.11.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.11.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.11.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.11.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.12.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.12.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.12.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.12.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.12.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.12.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.12.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.12.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.12.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.12.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.13.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.13.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 3\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.13.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.13.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.13.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.13.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.13.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.13.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.13.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.13.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.14.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.14.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.14.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.14.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.14.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.14.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.14.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.14.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.14.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.14.ln_1.weight torch.Size([4096])\n",
      "loading shards for part 4\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.15.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.15.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.15.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.15.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.15.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.15.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.15.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.15.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.15.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.15.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.16.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.16.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.16.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.16.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.16.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> transformer.h.16.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.16.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.16.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "loading shards for part 5\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.16.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.16.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.17.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.17.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.17.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.17.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.17.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.17.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.17.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.17.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.17.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.17.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.18.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.18.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.18.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.18.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.18.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.18.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "loading shards for part 6\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.18.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.18.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.18.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.18.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.19.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.19.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.19.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.19.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.19.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.19.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.19.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.19.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.19.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.19.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.2.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.2.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.2.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.2.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 7\n",
      "read from checkpoint\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.2.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.2.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.2.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.2.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.2.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.2.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.20.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.20.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.20.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.20.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.20.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.20.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.20.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.20.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.20.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.20.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.21.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.21.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 8\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.21.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.21.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.21.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.21.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.21.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.21.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.21.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.21.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.22.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.22.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.22.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.22.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.22.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.22.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.22.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.22.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.22.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.22.ln_1.weight torch.Size([4096])\n",
      "loading shards for part 9\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.23.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.23.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.23.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.23.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.23.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.23.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.23.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.23.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.23.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.23.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.24.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> transformer.h.24.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.24.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.24.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.24.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.24.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.24.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.24.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "loading shards for part 10\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.24.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.24.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.25.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.25.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.25.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.25.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.25.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.25.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.25.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.25.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.25.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.25.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.26.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.26.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.26.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.26.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.26.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.26.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "loading shards for part 11\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.26.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.26.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.26.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.26.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.27.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.27.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.27.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.27.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.27.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.27.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.27.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.27.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.27.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.27.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.3.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.3.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.3.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.3.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 12\n",
      "read from checkpoint\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.3.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.3.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.3.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.3.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.3.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.3.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.4.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.4.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.4.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.4.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.4.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.4.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.4.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.4.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.4.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.4.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.5.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.5.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "loading shards for part 13\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.5.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.5.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.5.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.5.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.5.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.5.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.5.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.5.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.6.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.6.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.6.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.6.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.6.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.6.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.6.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.6.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.6.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.6.ln_1.weight torch.Size([4096])\n",
      "loading shards for part 14\n",
      "read from checkpoint\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.7.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.7.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.7.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.7.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.7.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.7.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.7.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> transformer.h.7.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.7.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.7.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.8.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.8.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.8.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.8.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.8.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.8.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.8.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.8.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "loading shards for part 15\n",
      "read from checkpoint\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.8.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.8.ln_1.weight torch.Size([4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.9.attn.attention.q_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.9.attn.attention.v_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 4096, 512) to (1, 4096, 4096)\n",
      "> transformer.h.9.attn.attention.k_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 512, 4096) to (1, 4096, 4096)\n",
      "> transformer.h.9.attn.attention.out_proj.weight torch.Size([4096, 4096])\n",
      "< (8, 2048) to (1, 16384)\n",
      "> transformer.h.9.mlp.c_fc.bias torch.Size([16384])\n",
      "< (8, 4096, 2048) to (1, 4096, 16384)\n",
      "> transformer.h.9.mlp.c_fc.weight torch.Size([16384, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.9.mlp.c_proj.bias torch.Size([4096])\n",
      "< (8, 2048, 4096) to (1, 16384, 4096)\n",
      "> transformer.h.9.mlp.c_proj.weight torch.Size([4096, 16384])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.9.ln_1.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.h.9.ln_1.weight torch.Size([4096])\n",
      "< (8, 6300) to (1, 50400)\n",
      "> lm_head.bias torch.Size([50400])\n",
      "< (8, 4096, 6300) to (1, 4096, 50400)\n",
      "> lm_head.weight torch.Size([50400, 4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.ln_f.bias torch.Size([4096])\n",
      "< (8, 4096) to (4096,)\n",
      "> transformer.ln_f.weight torch.Size([4096])\n",
      "left over: [array([383502., 383502., 383502., 383502., 383502., 383502., 383502., 383502.], dtype=float32)]\n",
      "saving\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import io\n",
    "import os\n",
    "\n",
    "torch.set_printoptions(linewidth=130, sci_mode=False)\n",
    "np.set_printoptions(linewidth=130, suppress=True)\n",
    "\n",
    "layers = 28\n",
    "total_shards = 8\n",
    "ckpt_dir = \"step_383500/\"\n",
    "output_dir = \"j6b_ckpt\"\n",
    "\n",
    "def reshard(x, old_shape):\n",
    "    if len(x.shape) == 1:\n",
    "        # print(\"epoch\")\n",
    "        # print(x)\n",
    "        out = x[0:1]\n",
    "\n",
    "    elif len(x.shape) == 2:\n",
    "        #print(f\"LN/bias {x.shape}\")\n",
    "        #print(x[:, :16])\n",
    "\n",
    "        if (x[1:] == x[-1]).all():\n",
    "            #print(\"LN\")\n",
    "            if (x[1:] == 0).all() or (x[1:] == 1).all():\n",
    "                out = x[0:1]\n",
    "            else:\n",
    "                #print(\"shard bias\")\n",
    "                out = x[0:1] * 8#* x.shape[0] / old_shape[0]\n",
    "        else:\n",
    "            #print(\"bias\")\n",
    "            out = x.reshape(old_shape)\n",
    "\n",
    "        #print(out[:, :16])\n",
    "\n",
    "    elif len(x.shape) == 3:\n",
    "        #print(f\"weight {x.shape}\")\n",
    "        if x.shape[0] * x.shape[2] == old_shape[2]:\n",
    "            #print(\"case 1\")\n",
    "            out = jnp.transpose(x, (1, 0, 2)).reshape(old_shape)\n",
    "        elif x.shape[0] * x.shape[1] == old_shape[1]:\n",
    "            #print(\"case 2\")\n",
    "            out = x.reshape(old_shape)\n",
    "        else:\n",
    "            raise Exception(f\"unimplemented, {x.shape}, {old_shape}\")\n",
    "    else:\n",
    "        raise Exception(f\"unimplemented, {x}\")\n",
    "    #flattened, structure = jax.tree_flatten(out)\n",
    "    #return flattened\n",
    "    return out\n",
    "\n",
    "def get_old_shape(t, dim=2):\n",
    "    if len(t.shape) == 3:\n",
    "        shard_shape = t.shape\n",
    "        if dim == 1:\n",
    "            return (shard_shape[0] * shard_shape[1], shard_shape[2])\n",
    "        elif dim == 2:\n",
    "            return (shard_shape[1], shard_shape[0] * shard_shape[2])\n",
    "        else:\n",
    "            raise ValueError(f\"unsupported dim {dim}\")\n",
    "    if len(t.shape) == 2:\n",
    "        return (t.shape[1] * t.shape[0],)\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported shape {t.shape}\")\n",
    "\n",
    "def read_shard(ckpt_dir):\n",
    "    global part\n",
    "    out = []\n",
    "    idx = part\n",
    "    file_path = ckpt_dir + f\"{idx}.npz\"\n",
    "    #print(f\"-- {file_path}\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        buf = f.read()\n",
    "        f_io = io.BytesIO(buf)\n",
    "        deserialized = np.load(f_io)\n",
    "        for i in deserialized:\n",
    "            out.append(deserialized[i])\n",
    "            #print(deserialized[i].shape)\n",
    "    return out\n",
    "\n",
    "def save(ckpt):\n",
    "    try: os.mkdir(output_dir)\n",
    "    except: pass\n",
    "    checkpoint = {}\n",
    "    for i, x in enumerate(ckpt.items()):\n",
    "        checkpoint[x[0]] = f\"{output_dir}/b{i}.pt\"\n",
    "        torch.save(x[1], f\"{output_dir}/b{i}.pt\")\n",
    "    torch.save(checkpoint, f\"{output_dir}/m.pt\")\n",
    "\n",
    "unshard = None\n",
    "transforms = [(\"transformer.wte.bias\", None, None), (\"transformer.wte.weight\", unshard, 1)]\n",
    "\n",
    "checkpoint = {}\n",
    "\n",
    "layer_names = sorted(map(str, range(layers)))\n",
    "for layer in layer_names:\n",
    "    checkpoint[f\"transformer.h.{layer}.attn.attention.bias\"] = torch.tril(torch.ones(1, 1, 2048, 2048))\n",
    "    checkpoint[f\"transformer.h.{layer}.attn.attention.masked_bias\"] = torch.tensor(-1e9)\n",
    "    transforms.extend([\n",
    "        (f\"transformer.h.{layer}.attn.attention.q_proj.weight\", unshard, 2),\n",
    "        (f\"transformer.h.{layer}.attn.attention.v_proj.weight\", unshard, 2),\n",
    "        (f\"transformer.h.{layer}.attn.attention.k_proj.weight\", unshard, 2),\n",
    "        (f\"transformer.h.{layer}.attn.attention.out_proj.weight\", unshard, 1),\n",
    "        (f\"transformer.h.{layer}.mlp.c_fc.bias\", unshard, 1),\n",
    "        (f\"transformer.h.{layer}.mlp.c_fc.weight\", unshard, 2),\n",
    "        (f\"transformer.h.{layer}.mlp.c_proj.bias\", None, None),\n",
    "        (f\"transformer.h.{layer}.mlp.c_proj.weight\", unshard, 1),\n",
    "        (f\"transformer.h.{layer}.ln_1.bias\", None, None),\n",
    "        (f\"transformer.h.{layer}.ln_1.weight\", None, None),\n",
    "    ])\n",
    "transforms.extend([\n",
    "    (\"lm_head.bias\", unshard, 1),\n",
    "    (\"lm_head.weight\", unshard, 2),\n",
    "    (\"transformer.ln_f.bias\", None, None),\n",
    "    (\"transformer.ln_f.weight\", None, None),\n",
    "])\n",
    "\n",
    "part = 0\n",
    "element = 0\n",
    "while len(transforms) > 0:\n",
    "    print(f\"loading shards for part {part}\")\n",
    "    shards = list(map(read_shard, [f\"{ckpt_dir}shard_{i}/\" for i in range(total_shards)]))\n",
    "    print(f\"read from checkpoint\")\n",
    "\n",
    "    unsharded = []\n",
    "\n",
    "    for all_shards in zip(*shards):\n",
    "        x = np.stack(all_shards)\n",
    "        # No idea why this is V2...?\n",
    "        if x.dtype == np.dtype('V2'):\n",
    "            x.dtype = jnp.bfloat16\n",
    "        x = x.astype(np.float32)\n",
    "        unsharded.append(x)\n",
    "        #print(f\"unsharded: {x.shape}\")\n",
    "\n",
    "    while len(transforms) > 0 and len(unsharded) > 0:\n",
    "        transform = transforms.pop(0)\n",
    "        params = unsharded.pop(0)\n",
    "        if transform[2] is not None:\n",
    "            old_shape = (1,) + get_old_shape(params, transform[2])\n",
    "        else:\n",
    "            old_shape = (params.shape[1],)\n",
    "        print(f\"< {params.shape} to {old_shape}\")\n",
    "        params = reshard(params, old_shape).squeeze(0).T\n",
    "        params = torch.tensor(params.copy()).half()\n",
    "        if params.isnan().any() or params.isinf().any():\n",
    "            raise ValueError(f\"fp16 over/underflow at {part} {element}\")\n",
    "        checkpoint[transform[0]] = params\n",
    "        print(f\"> {transform[0]} {params.shape}\")\n",
    "        element += 1\n",
    "    part += 1\n",
    "\n",
    "checkpoint['transformer.wte.weight'] = (checkpoint['transformer.wte.weight'].T + checkpoint['transformer.wte.bias'])\n",
    "del checkpoint['transformer.wte.bias']\n",
    "\n",
    "print(f\"left over: {unsharded}\")\n",
    "print(\"saving\")\n",
    "torch.save(checkpoint, \"./gpt-j-6B/pytorch_model.bin\") # load as in: https://github.com/finetuneanon/misc/blob/main/SizeTest.ipynb\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f8bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, AutoConfig, GPT2Tokenizer\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6475e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will need at least 13-14GB of Vram\n",
    "if torch.cuda.is_available():\n",
    "    model = GPTNeoForCausalLM.from_pretrained(\"./gpt-j-6B\").half().cuda()\n",
    "else:\n",
    "    model = GPTNeoForCausalLM.from_pretrained(\"./gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f75f0a4",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f731069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76da2f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (c_proj): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.half().cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030d4615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello my name is Blake and\"\n",
    "input_ids = tokenizer.encode(str(input_text), return_tensors='pt').cuda()\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=20,\n",
    "    top_p=0.7,\n",
    "    top_k=0,\n",
    "    temperature=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f783672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is Blake and\n",
      "I'm going to be talking about the\n",
      "significance of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a4cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
